{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# helpers\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tool functions #####\n",
    "\n",
    "# plot an image in a subplot\n",
    "def subplot_image(image, label, nrows=1, ncols=1, iplot=0):\n",
    "    plt.subplot(nrows, ncols, iplot + 1)\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.xlabel(label)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "# plot a bar chart in a subplot\n",
    "def subplot_bar(data, true_label, nrows=1, ncols=1, iplot=0):\n",
    "    plt.subplot(nrows, ncols, iplot + 1)\n",
    "    chart = plt.bar(np.arange(len(data)), data, color='gray')\n",
    "    predicted_label = np.argmax(data)\n",
    "    chart[predicted_label].set_color('red')\n",
    "    chart[true_label].set_color('green')\n",
    "    plt.xticks(np.arange(len(data)))\n",
    "    plt.yticks([])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.gca().set_aspect(len(data))\n",
    "    plt.title('Probability', fontsize=12)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset: Fashion-MNIST\n",
    "![fashion.png](https://i.ibb.co/N7wPnqs/fashion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# normalise images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# string labels\n",
    "string_labels = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# info\n",
    "print(\"number of training data: %d\" % len(train_labels))\n",
    "print(\"number of test data: %d\" % len(test_labels))\n",
    "print(\"image pixels: %s\" % str(train_images[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "nrows = 4\n",
    "ncols = 8\n",
    "plt.figure(dpi=100, figsize=(ncols * 2, nrows * 2.2))\n",
    "for i in np.arange(nrows * ncols):\n",
    "    title = \"%d: %s\" % (train_labels[i], string_labels[train_labels[i]])\n",
    "    subplot_image(train_images[i], title, nrows, ncols, i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Supervised: DNN\n",
    "\n",
    "We start with a simple DNN that has only one hidden layer. This is a classification problem, an instance of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DNN\n",
    "Our first DNN looks like this:\n",
    "![dense.jpeg](https://i.ibb.co/W0dDDfm/dense-001.jpg)\n",
    "\n",
    "#### Concepts to learn:\n",
    "* Input and output layers\n",
    "* Hidden layers\n",
    "* Dense layers\n",
    "* Activation functionn\n",
    "* Dropout and overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "dnn = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "], name='DNN_01')\n",
    "\n",
    "# print summary\n",
    "dnn.summary()\n",
    "\n",
    "# save initial weights\n",
    "dnn_initial_weights = dnn.get_weights().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the DNN\n",
    "#### Concepts to learn:\n",
    "* Optimizer\n",
    "* Loss function\n",
    "* Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "dnn.compile(optimizer='adam',\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the DNN\n",
    "#### Concepts to learn:\n",
    "* Epoch\n",
    "* Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save time, you can load the trained model instead of doing the training\n",
    "# this training takes about 1 minute (epochs=20, batch_size=32)\n",
    "just_load_trained = True\n",
    "\n",
    "if just_load_trained:\n",
    "    # load model\n",
    "    dnn.load_weights('trained_models/dnn01/trained.h5')\n",
    "    # load training history\n",
    "    with open('trained_models/dnn01/history.bin', 'rb') as fin:\n",
    "        training_history = pickle.load(fin)\n",
    "else:\n",
    "    # reset to initial weights\n",
    "    dnn.set_weights(dnn_initial_weights)\n",
    "    # train model\n",
    "    training_history = dnn.fit(train_images, train_labels, epochs=20, batch_size=32)\n",
    "    training_history = training_history.history\n",
    "    # save model\n",
    "    dnn.save_weights('trained_models/dnn01/trained.h5')\n",
    "    # save training history\n",
    "    with open('trained_models/dnn01/history.bin', 'wb') as fout:\n",
    "        pickle.dump(training_history, fout)\n",
    "        \n",
    "# plot training history\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(training_history['loss'], label='Loss')\n",
    "plt.plot(training_history['accuracy'], label='Accuracy')\n",
    "plt.xticks(np.arange(0, len(training_history['loss']) + 1, 2))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss or accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the DNN with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "test_loss, test_acc = dnn.evaluate(test_images, test_labels)\n",
    "print('\\nTest loss:', test_loss)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append a softmax layer to normalise the output\n",
    "probability_model = keras.Sequential([dnn, keras.layers.Softmax()])\n",
    "\n",
    "# use test data to make predictions\n",
    "test_probabilities = probability_model.predict(test_images)\n",
    "test_pred_labels = np.argmax(test_probabilities, axis=1)\n",
    "\n",
    "# plot the test images along with their predicted and true labels.\n",
    "nrows = 5\n",
    "ncols = 3\n",
    "plt.figure(dpi=100, figsize=(6 * ncols, 2.5 * nrows))\n",
    "np.random.seed(0)\n",
    "for iplot, itest in enumerate(np.random.randint(0, len(test_labels), nrows * ncols)):\n",
    "    # plot image\n",
    "    title = \"%d: %s\" % (test_labels[itest], string_labels[test_labels[itest]])\n",
    "    subplot_image(test_images[itest], title, nrows, ncols * 3, iplot * 3)\n",
    "    # plot bar chart of probability\n",
    "    subplot_bar(test_probabilities[itest], test_labels[itest], nrows, ncols * 3, iplot * 3 + 1)\n",
    "    # additional texts\n",
    "    subplot_image([[0]], '', nrows, ncols * 3, iplot * 3 + 2)\n",
    "    correct = test_labels[itest] == test_pred_labels[itest]\n",
    "    textcolor = 'g' if correct else 'r'\n",
    "    plt.text(-.5, -.3, \"Truth: %s\" % string_labels[test_labels[itest]])\n",
    "    plt.text(-.5, -.1, \"Prediction: %s\" % string_labels[test_pred_labels[itest]], c=textcolor)\n",
    "    plt.text(-.5, .1, \"Probability: %.0f%%\" % (test_probabilities[itest].max() * 100), c=textcolor)\n",
    "    plt.text(-.5, .3, \"CORRECT\" if correct else 'INCORRECT', c=textcolor, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supervised: CNN\n",
    "\n",
    "For the same classification problem, we now use a CNN like this:\n",
    "![layer.jpeg](https://i.ibb.co/VDJ301m/layer.jpg)\n",
    "\n",
    "#### Concepts to learn:\n",
    "* Convolutional layers\n",
    "* Max pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "cnn = keras.models.Sequential(name='CNN')\n",
    "# 1 input => convolution\n",
    "cnn.add(keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "# 2 max pooling\n",
    "cnn.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "# 3 convolution\n",
    "cnn.add(keras.layers.Conv2D(32, (5, 5), activation='relu'))\n",
    "# 4 max pooling\n",
    "cnn.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "# 5 flatten\n",
    "cnn.add(keras.layers.Flatten())\n",
    "# 6 dense\n",
    "cnn.add(keras.layers.Dense(64, activation='relu'))\n",
    "# 7 dense => output\n",
    "cnn.add(keras.layers.Dense(10))\n",
    "\n",
    "# print summary\n",
    "cnn.summary()\n",
    "\n",
    "# save initial weights\n",
    "cnn_initial_weights = cnn.get_weights().copy()\n",
    "\n",
    "# optimizer, loss, metrics\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append channel dimension because we only have one channel (gray-scale)\n",
    "def append_channel_dim(img):\n",
    "    return np.array([img]).transpose([1, 2, 3, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save time, you can load the trained model instead of doing the training\n",
    "# this training takes about 6 minutes (epochs=20, batch_size=32)\n",
    "just_load_trained = True\n",
    "\n",
    "if just_load_trained:\n",
    "    # load model\n",
    "    cnn.load_weights('trained_models/cnn01/trained.h5')\n",
    "    # load training history\n",
    "    with open('trained_models/cnn01/history.bin', 'rb') as fin:\n",
    "        training_history = pickle.load(fin)\n",
    "else:\n",
    "    # reset to initial weights\n",
    "    cnn.set_weights(cnn_initial_weights)\n",
    "    # train model\n",
    "    training_history = cnn.fit(append_channel_dim(train_images), train_labels, \n",
    "                               epochs=20, batch_size=32)\n",
    "    training_history = training_history.history\n",
    "    # save model\n",
    "    cnn.save_weights('trained_models/cnn01/trained.h5')\n",
    "    # save training history\n",
    "    with open('trained_models/cnn01/history.bin', 'wb') as fout:\n",
    "        pickle.dump(training_history, fout)\n",
    "        \n",
    "# plot training history\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(training_history['loss'], label='Loss')\n",
    "plt.plot(training_history['accuracy'], label='Accuracy')\n",
    "plt.xticks(np.arange(0, len(training_history['loss']) + 1, 2))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss or accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "test_loss, test_acc = cnn.evaluate(append_channel_dim(test_images), test_labels, verbose=1)\n",
    "print('\\nTest loss:', test_loss)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append a softmax layer to normalise the output\n",
    "probability_model = keras.Sequential([cnn, keras.layers.Softmax()])\n",
    "\n",
    "# use test data to make predictions\n",
    "test_probabilities = probability_model.predict(append_channel_dim(test_images))\n",
    "test_pred_labels = np.argmax(test_probabilities, axis=1)\n",
    "\n",
    "# plot the test images along with their predicted and true labels.\n",
    "nrows = 5\n",
    "ncols = 3\n",
    "plt.figure(dpi=100, figsize=(6 * ncols, 2.5 * nrows))\n",
    "np.random.seed(0)\n",
    "for iplot, itest in enumerate(np.random.randint(0, len(test_labels), nrows * ncols)):\n",
    "    # plot image\n",
    "    title = \"%d: %s\" % (test_labels[itest], string_labels[test_labels[itest]])\n",
    "    subplot_image(test_images[itest], title, nrows, ncols * 3, iplot * 3)\n",
    "    # plot bar chart of probability\n",
    "    subplot_bar(test_probabilities[itest], test_labels[itest], nrows, ncols * 3, iplot * 3 + 1)\n",
    "    # additional texts\n",
    "    subplot_image([[0]], '', nrows, ncols * 3, iplot * 3 + 2)\n",
    "    correct = test_labels[itest] == test_pred_labels[itest]\n",
    "    textcolor = 'g' if correct else 'r'\n",
    "    plt.text(-.5, -.3, \"Truth: %s\" % string_labels[test_labels[itest]])\n",
    "    plt.text(-.5, -.1, \"Prediction: %s\" % string_labels[test_pred_labels[itest]], c=textcolor)\n",
    "    plt.text(-.5, .1, \"Probability: %.0f%%\" % (test_probabilities[itest].max() * 100), c=textcolor)\n",
    "    plt.text(-.5, .3, \"CORRECT\" if correct else 'INCORRECT', c=textcolor, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Semi-supervised: Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> What is autoencoder? </strong>\n",
    "\n",
    "An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name. -- from Wikipedia\n",
    "\n",
    "![autoencoder.jpg](https://i.ibb.co/Zg2TNGP/Screenshot-2020-07-12-at-4-21-09-AM.png)\n",
    "\n",
    "#### Concepts to learn:\n",
    "* Autoencoder\n",
    "* Encoder\n",
    "* Decoder\n",
    "* dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target class for training\n",
    "We train the autoencoder using images from one <strong> target class </strong>, such as \"Sneaker\". The trained autoencoder should be able to distinguish whether a test image belongs to the target class based on the reconstruction error: an image belonging to the target class tends to have a small reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a target class for training\n",
    "# 'T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "# 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "target_class = 'Sneaker'\n",
    "target_label = string_labels.index(target_class)\n",
    "\n",
    "# size of the \"bottleneck\"\n",
    "bottleneck = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image subset of the chosen class\n",
    "target_train_images = train_images[np.where(train_labels == target_label)[0]]\n",
    "target_test_images = test_images[np.where(test_labels == target_label)[0]]\n",
    "print('Total number of images labelled \"%s\":' % (target_class,))\n",
    "print('%d in training data' % (target_train_images.shape[0],))\n",
    "print('%d in test data' % (target_test_images.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "autoencoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='selu'),\n",
    "    keras.layers.Dense(128, activation='selu'),\n",
    "    keras.layers.Dense(bottleneck, activation='selu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(128, activation='selu'),\n",
    "    keras.layers.Dense(256, activation='selu'),\n",
    "    keras.layers.Dense(784, activation='sigmoid'),\n",
    "    keras.layers.Reshape((28, 28))\n",
    "], name='Autoencoder')\n",
    "\n",
    "# print summary\n",
    "autoencoder.summary()\n",
    "\n",
    "# save initial weights\n",
    "ae_initial_weights = autoencoder.get_weights().copy()\n",
    "\n",
    "# compile\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save time, you can load the trained model instead of doing the training\n",
    "# this training takes about 5 minutes (epochs=300, batch_size=32)\n",
    "just_load_trained = True\n",
    "\n",
    "if just_load_trained:\n",
    "    # load model\n",
    "    autoencoder.load_weights('trained_models/ae01/trained_%s_%s.h5' % (target_class, bottleneck))\n",
    "    # load training history\n",
    "    with open('trained_models/ae01/history_%s_%s.bin' % (target_class, bottleneck), 'rb') as fin:\n",
    "        training_history = pickle.load(fin)\n",
    "else:\n",
    "    # reset to initial weights\n",
    "    autoencoder.set_weights(ae_initial_weights)\n",
    "    # train model\n",
    "    training_history = autoencoder.fit(target_train_images, target_train_images,\n",
    "                                       epochs=300, batch_size=32,\n",
    "                                       validation_data=(target_test_images, target_test_images))\n",
    "    training_history = training_history.history\n",
    "    # save model\n",
    "    autoencoder.save_weights('trained_models/ae01/trained_%s_%s.h5' % (target_class, bottleneck))\n",
    "    # save training history\n",
    "    with open('trained_models/ae01/history_%s_%s.bin' % (target_class, bottleneck), 'wb') as fout:\n",
    "        pickle.dump(training_history, fout)\n",
    "        \n",
    "# plot training history\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(training_history['loss'], label='Loss')\n",
    "plt.xticks(np.arange(0, len(training_history['loss']) + 1, 50))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss or accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct test images, evaluate loss and classify\n",
    "\n",
    "A small loss (or reconstruction error) indicates a high probability that a test image belongs to the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct training and test images\n",
    "reconstructed_test_images = autoencoder.predict(test_images)\n",
    "\n",
    "# specify a threshold loss\n",
    "# an image belongs to the target class if loss is smaller than this threshold loss\n",
    "threshold_loss = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot original and reconstructed test images\n",
    "nrows = 5\n",
    "ncols = 3\n",
    "plt.figure(dpi=100, figsize=(6 * ncols, 2.5 * nrows))\n",
    "np.random.seed(0)\n",
    "for iplot, itest in enumerate(np.random.randint(0, len(test_images), nrows * ncols)):\n",
    "    # plot original image\n",
    "    subplot_image(test_images[itest], 'origional', nrows, ncols * 3, iplot * 3)\n",
    "    # plot reconstructed image\n",
    "    subplot_image(reconstructed_test_images[itest], 'reconstructed', nrows, ncols * 3, iplot * 3 + 1)\n",
    "    # additional texts\n",
    "    subplot_image([[0]], '', nrows, ncols * 3, iplot * 3 + 2)\n",
    "    # truth\n",
    "    truth = (test_labels[itest] == target_label)\n",
    "    # loss evaluation\n",
    "    loss = autoencoder.evaluate(np.array([test_images[itest]]), \n",
    "                                np.array([test_images[itest]]), verbose=0)\n",
    "    # prediction\n",
    "    predict = (loss < threshold_loss)\n",
    "    # correct or not?\n",
    "    correct = (truth == predict)\n",
    "    textcolor = 'g' if correct else 'r'\n",
    "    plt.text(-.5, -.3, 'Truth: %s' % string_labels[test_labels[itest]])\n",
    "    plt.text(-.5, -.1, 'Loss: %.2f' % loss, c=textcolor)\n",
    "    plt.text(-.5, .2, 'Prediction:\\n%s' % (target_class if predict else 'Non-%s' % target_class), c=textcolor)\n",
    "    plt.text(-.5, .4, \"CORRECT\" if correct else 'INCORRECT', c=textcolor, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new synthetic images by changing the bottleneck features\n",
    "\n",
    "A trained autoencoder can also be used to decompress an image (using the encoder) and to generate new synthetic images (using the decoder) after modifying the key features in the bottleneck layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the encoder and decoder (the first and second half of our autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder = keras.models.Sequential([\n",
    "    autoencoder.layers[0],\n",
    "    autoencoder.layers[1],\n",
    "    autoencoder.layers[2],\n",
    "    autoencoder.layers[3]\n",
    "], name='Encoder')\n",
    "\n",
    "# decoder\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(bottleneck,)),\n",
    "    autoencoder.layers[-4],\n",
    "    autoencoder.layers[-3],\n",
    "    autoencoder.layers[-2],\n",
    "    autoencoder.layers[-1]\n",
    "], name='Decoder')\n",
    "\n",
    "# print summary\n",
    "encoder.summary()\n",
    "print('\\n')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the bottleneck using the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "target_train_images_encoded = encoder.predict(target_train_images)\n",
    "\n",
    "# reconstruct training images\n",
    "reconstructed_target_train_images = autoencoder.predict(target_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick an image index here (0~5999)\n",
    "image_index = 1000\n",
    "\n",
    "# original bottleneck data\n",
    "encoded_original = target_train_images_encoded[image_index]\n",
    "print('Key features at the bottleneck:')\n",
    "print(encoded_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new synthetic images using the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the key features\n",
    "encoded_modified = encoded_original.copy()\n",
    "encoded_modified[0] = 2\n",
    "encoded_modified[1] = 2\n",
    "\n",
    "# decode modified\n",
    "decoded_modified = decoder.predict(np.array([encoded_modified]))[0]\n",
    "\n",
    "# plot images\n",
    "plt.figure(dpi=100, figsize=(10, 3))\n",
    "subplot_image(target_train_images[image_index], 'Original', 1, 3, 0)\n",
    "subplot_image(reconstructed_target_train_images[image_index], 'Reconstructed original', 1, 3, 1)\n",
    "subplot_image(decoded_modified, 'Reconstructed modified', 1, 3, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use widgets for dynamic modification\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sliders\n",
    "sliders = []\n",
    "argdict = {}\n",
    "for i in np.arange(bottleneck):\n",
    "    sliders.append(widgets.FloatSlider(min=-5, max=5, step=.01, value=encoded_original[i], \n",
    "                                       description='Feature %d:' % (i + 1,),\n",
    "                                       layout=widgets.Layout(width='auto', height='auto')))\n",
    "    # associate sliders with varaibles passed to the respondent function\n",
    "    argdict['v%d' % (i + 1)] = sliders[i]\n",
    "ui = widgets.VBox(sliders)\n",
    "\n",
    "# the respondent function\n",
    "# TODO: make argument count consistent with bottleneck size\n",
    "def respond(v1, v2, v3, v4, v5, v6, v7, v8):\n",
    "    # decode\n",
    "    encoded_modified = np.array([v1, v2, v3, v4, v5, v6, v7, v8])\n",
    "    decoded_modified = decoder.predict(np.array([encoded_modified]))[0]\n",
    "    # plot images\n",
    "    plt.figure(dpi=100, figsize=(10, 3))\n",
    "    subplot_image(target_train_images[image_index], 'Original', 1, 3, 0)\n",
    "    subplot_image(reconstructed_target_train_images[image_index], 'Reconstructed original', 1, 3, 1)\n",
    "    subplot_image(decoded_modified, 'Reconstructed modified', 1, 3, 2)\n",
    "    plt.show()\n",
    "\n",
    "# craete UI\n",
    "out = widgets.interactive_output(respond, argdict)\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Unsupervised: Autoencoder + K-means\n",
    "\n",
    "In this example, we use K-means to cluster the images. Unsupervised clustering is challenged by a large input dimensionality (such as 28 x 28 here), so we first use an autoencoder to first reduce the input dimensionality and then perform clustering in the bottleneck feature space.\n",
    "\n",
    "#### Concepts to learn:\n",
    "* Clustering\n",
    "* K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import K-means from sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the autoencoder with all the 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the \"bottleneck\"\n",
    "bottleneck_all = 8\n",
    "\n",
    "# create model\n",
    "ae_all = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='selu'),\n",
    "    keras.layers.Dense(128, activation='selu'),\n",
    "    keras.layers.Dense(bottleneck_all, activation='selu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(128, activation='selu'),\n",
    "    keras.layers.Dense(256, activation='selu'),\n",
    "    keras.layers.Dense(784, activation='sigmoid'),\n",
    "    keras.layers.Reshape((28, 28))\n",
    "], name='Autoencoder-All')\n",
    "\n",
    "# print summary\n",
    "ae_all.summary()\n",
    "\n",
    "# save initial weights\n",
    "ae_all_initial_weights = ae_all.get_weights().copy()\n",
    "\n",
    "# compile\n",
    "ae_all.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to save time, you can load the trained model instead of doing the training\n",
    "# this training takes about 9 minutes (epochs=100, batch_size=64)\n",
    "just_load_trained = True\n",
    "\n",
    "if just_load_trained:\n",
    "    # load model\n",
    "    ae_all.load_weights('trained_models/ae02/trained_%s.h5' % (bottleneck_all,))\n",
    "    # load training history\n",
    "    with open('trained_models/ae02/history_%s.bin' % (bottleneck_all,), 'rb') as fin:\n",
    "        training_history = pickle.load(fin)\n",
    "else:\n",
    "    # reset to initial weights\n",
    "    ae_all.set_weights(ae_all_initial_weights)\n",
    "    # train model\n",
    "    training_history = ae_all.fit(train_images, train_images, epochs=100, batch_size=64,\n",
    "                                  validation_data=(test_images, test_images))\n",
    "    training_history = training_history.history\n",
    "    # save model\n",
    "    ae_all.save_weights('trained_models/ae02/trained_%s.h5' % (bottleneck_all,))\n",
    "    # save training history\n",
    "    with open('trained_models/ae02/history_%s.bin' % (bottleneck_all,), 'wb') as fout:\n",
    "        pickle.dump(training_history, fout)\n",
    "        \n",
    "# plot training history\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(training_history['loss'], label='Loss')\n",
    "plt.xticks(np.arange(0, len(training_history['loss']) + 1, 10))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss or accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract encoder\n",
    "encoder_all = keras.models.Sequential([\n",
    "    ae_all.layers[0],\n",
    "    ae_all.layers[1],\n",
    "    ae_all.layers[2],\n",
    "    ae_all.layers[3]\n",
    "], name='Encoder-All')\n",
    "\n",
    "# encode images\n",
    "train_images_encoded = encoder_all.predict(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the encoded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "kmeans_model = KMeans(n_clusters=10, max_iter=300)\n",
    "\n",
    "# train and predict\n",
    "kmeans_labels = kmeans_model.fit_predict(train_images_encoded)\n",
    "\n",
    "# print scores\n",
    "print('Homogeneity score = %.3f' % sklearn.metrics.homogeneity_score(train_labels, kmeans_labels))\n",
    "print('Completeness score = %.3f' % sklearn.metrics.completeness_score(train_labels, kmeans_labels))\n",
    "print('V-measure score = %.3f' % sklearn.metrics.v_measure_score(train_labels, kmeans_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot clustered images\n",
    "# NOTE: the cluster lables are NOT associated with the orignal class labels\n",
    "n_image_per_cluster = 15\n",
    "n_cluster = 10\n",
    "for cluster_label in np.arange(n_cluster):\n",
    "    # get indices of the first n_image_per_cluster in this cluster\n",
    "    itrains = np.where(kmeans_labels == cluster_label)[0][0:n_image_per_cluster]\n",
    "    fig = plt.figure(dpi=100, figsize=(n_image_per_cluster * 2, n_cluster * 2))\n",
    "    print('\\n\\nImages in cluster %d:' % cluster_label)\n",
    "    for iplot, itrain in enumerate(itrains):\n",
    "        subplot_image(train_images[itrain], string_labels[train_labels[itrain]], \n",
    "                      n_cluster, n_image_per_cluster, iplot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The about results show that\n",
    "* similar-looking images such as Shirts, Coats and Pullovers are not well distinguished\n",
    "* Bags with and without handles are clustered into two subclasses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show clustering in feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of data to show\n",
    "show_ndata = 500\n",
    "\n",
    "# clusters to show\n",
    "show_clusters = np.array([1, 2, 3])\n",
    "\n",
    "# find the data subset\n",
    "show_data_indices = np.where(np.isin(kmeans_labels, show_clusters))[0][0:show_ndata]\n",
    "\n",
    "# normalise features to [0, 1]\n",
    "train_images_encoded_norm = (train_images_encoded - train_images_encoded.min()) / \\\n",
    "                            (train_images_encoded.max() - train_images_encoded.min())\n",
    "# for better visualisation\n",
    "train_images_encoded_norm = np.power(train_images_encoded_norm, .5)\n",
    "\n",
    "# plot\n",
    "plt.figure(dpi=100, figsize=(15, 15))\n",
    "iplot = 0\n",
    "for feature_x in np.arange(bottleneck_all):\n",
    "    for feature_y in np.arange(bottleneck_all):\n",
    "        plt.subplot(bottleneck_all, bottleneck_all, iplot + 1)\n",
    "        x = train_images_encoded_norm[show_data_indices, feature_x]\n",
    "        y = train_images_encoded_norm[show_data_indices, feature_y]\n",
    "        plt.scatter(x, y, c=kmeans_labels[show_data_indices], s=10, cmap=plt.cm.Paired)\n",
    "        plt.xlim(-.05, .95)\n",
    "        plt.ylim(-.05, .95)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        iplot += 1\n",
    "        if feature_y == 0:\n",
    "            plt.ylabel('Feature %d' % feature_x)\n",
    "        if feature_x == 0:\n",
    "            plt.gca().xaxis.set_label_position('top') \n",
    "            plt.xlabel('Feature %d' % feature_y)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
